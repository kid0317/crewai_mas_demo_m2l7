# 小红书爆款笔记生成 Agent 实战课程 — 逐字稿

> 课程时长：约 40 分钟
> 配套代码仓库：本项目（crewai_mas_demo_m2l7）

---

## 开场导入（0:00 – 2:00）

大家好，欢迎来到本节实战课程。

在前面的课程里，我们已经学习了 CrewAI 的核心概念——Agent、Task、Crew，以及如何用它们来编排多智能体协作。今天这节课，我们要把这些知识落地到一个真实的项目中：**搭建一个小红书爆款笔记生成系统**。

先来看我们最终要实现的效果。用户通过一个 API 接口，上传几张图片，再写一句话描述自己的创作意图——比如"我想分享最近开始用地中海饮食减脂"——系统就会自动生成一份完整的小红书笔记报告。这份报告包含：经过 SEO 优化的标题、正文内容、推荐的标签、图片的发布顺序，以及每张图片应该怎么编辑的具体方案。

这背后是 5 个 Agent 在协作。有视觉分析师负责看图，有图片编辑师出编辑方案，有增长策略专家做内容策划，有文案撰写师写正文，还有 SEO 专家做搜索优化。它们分三个阶段协作，先并发处理图片，再串行创作内容。

今天我们就来一步步搭建这个系统。我会按照实际开发的顺序来讲：**先定义数据模型，再设计 Agent，然后构建 Task，接着做流程编排，最后集成到 API**。

---

## 第一章：项目架构设计（2:00 – 7:00）

### 1.1 分层架构

我们先来看整个项目的分层架构。打开项目目录，大家可以看到 `src/app/` 下面的目录结构：

```
src/app/
├── api/v1/           # API 层
├── services/         # 服务层
├── crews/xhs_note/   # 编排层（agents, tasks, flows）
├── crews/config/     # 配置层（agents.yaml, tasks.yaml）
├── crews/llm/        # LLM 层
├── schemas/          # 数据模型层
└── core/             # 基础设施（配置、安全、图片工具）
```

这是一个典型的分层架构，每一层只依赖它下面的层。最上面是 API 层，接收 HTTP 请求；Service 层负责业务逻辑，比如图片保存和压缩；Flow 层负责编排多个 Agent 的协作流程；最底下是 Agent、Task 和 LLM。

这样分层的好处是职责清晰，改任何一层都不会影响其他层。比如以后你想把 API 框架从 FastAPI 换成别的，只需要改 API 层，Service 层以下完全不用动。

### 1.2 请求链路

我们来过一遍一个完整请求的链路。

当用户发起 `POST /api/v1/xhs/notes/report` 请求时：

**第一步**，请求到达 API 层。`api/v1/xhs_note.py` 接收 multipart 表单数据，解析出 `idea_text` 文本和多个 `images` 文件。

**第二步**，API 层调用 Service 层的 `generate_xhs_note_report()` 函数。Service 层负责把上传的图片存到临时目录，用 Pillow 做压缩——把长边缩到 1024 像素、JPEG 质量 85——然后构建一个领域模型 `XhsNoteIdeaRequest`，包含用户意图和图片列表。

**第三步**，Service 层调用 Flow 层的 `run_xhs_note_flow()`。这是核心，流程编排会按三个阶段执行：先做视觉分析、再做编辑方案、最后做内容创作。每个阶段都创建一个 Crew 来执行。

**第四步**，Flow 层返回最终的报告字符串，Service 层清理临时文件，API 层包装成统一的 JSON 响应返回给用户。

现在大家对整体流程有了概念。我们接下来开始写代码，首先从数据模型开始。

### 1.3 关键文件清单

在开始之前，我列一下我们今天会涉及的核心文件，大家可以对照着看：

- `schemas/xhs_note.py` — 所有 Pydantic 数据模型
- `crews/config/agents.yaml` — Agent 角色文案配置
- `crews/config/tasks.yaml` — Task 描述模板配置
- `crews/xhs_note/agents.py` — Agent 工厂函数
- `crews/xhs_note/tasks.py` — Task 工厂函数
- `crews/xhs_note/flows.py` — 三阶段流程编排
- `services/xhs_note_service.py` — 业务逻辑
- `api/v1/xhs_note.py` — HTTP 端点

---

## 第二章：数据模型设计（7:00 – 13:00）

### 2.1 为什么先定义数据模型

在动手写 Agent 之前，我们要先想清楚一个问题：**Agent 之间怎么传递信息？**

在多 Agent 系统里，Agent 不是孤立工作的。视觉分析师分析完图片，编辑师要基于分析结果来出编辑方案；策略专家做完策划，文案师要基于策划来写内容。这就需要一种"接口契约"——上游 Agent 输出什么格式，下游 Agent 期望收到什么格式。

在 CrewAI 里，这个契约就是 **Pydantic 模型**。我们通过 `output_pydantic` 参数告诉 Task："你的 Agent 必须输出能被解析为这个 Pydantic 模型的 JSON"。CrewAI 会自动把 LLM 的文本输出解析成结构化的 Python 对象。

所以，先定义数据模型，相当于先画好每个 Agent 的输入输出接口，然后再去实现它们。

### 2.2 输入模型

打开 `schemas/xhs_note.py`，我们从输入模型开始看。

```python
class XhsImageInput(BaseModel):
    """单张图片信息。"""
    image_id: str       # 如 "img_0", "img_1"
    file_name: str      # 原始文件名
    local_path: str     # 压缩后的本地路径
```

这是单张图片的元信息。`image_id` 是我们在保存时生成的，用来在整个流程中唯一标识一张图片。`local_path` 是图片压缩后存在磁盘上的路径，后面多模态 Agent 会通过这个路径加载图片。

```python
class XhsNoteIdeaRequest(BaseModel):
    """用户创作请求。"""
    idea_text: str                    # 用户的一句话创作意图
    images: List[XhsImageInput]      # 上传的图片列表
```

这是用户请求的领域模型——一个意图文本加一组图片。注意这不是 HTTP 请求模型，而是 Service 层处理完上传文件后构建的内部模型。

### 2.3 Agent 输出模型

接下来是最核心的部分——每个 Agent 的输出模型。我们一个个来看。

**第一个：视觉分析结果**

```python
class XhsImageVisualAnalysis(BaseModel):
    """单张图片的视觉分析结果。"""
    image_id: str
    file_name: str
    subject_description: str      # 主体内容的客观描述
    atmosphere_vibe: str          # 画面氛围与情绪基调
    visual_details: List[str]     # 3个以上容易忽略的重要细节
    image_quality_score: str      # 1-10分 + 理由
    highlight_feature: str        # 视觉锚点及其作为钩子的原因
```

这个模型定义了视觉分析师要输出什么。注意看字段设计的思路：`subject_description` 是客观描述主体内容，`atmosphere_vibe` 是感性的氛围判断，`visual_details` 要求列出 3 个以上容易忽略的细节——这是在引导 LLM 去做更深入的观察。`image_quality_score` 不只是打分，还要附上理由。`highlight_feature` 要指出视觉锚点——也就是最能抓眼的元素。

**第二个：图片编辑方案**

```python
class XhsImageEditPlan(BaseModel):
    """单张图片的编辑/P图方案。"""
    image_id: str
    file_name: str
    overall_edit_strategy: str                # 整体编辑策略
    crop_suggestion: str                      # 裁剪建议
    light_color_adjustment: str               # 亮度/对比度/饱和度
    filter_suggestion: str                    # 滤镜推荐
    text_overlay_suggestion: str              # 文字叠加建议
    beauty_adjustment_suggestion: str         # 美颜建议
    is_recommended_as_cover: bool             # 是否推荐为首图
    risk_and_pitfall_notes: str               # 风险与合规提醒
```

这个模型覆盖了小红书图片编辑的方方面面。特别注意 `is_recommended_as_cover` 这个布尔字段——编辑师会判断哪张图最适合做首图。`risk_and_pitfall_notes` 提醒可能的平台审核风险，比如过度美颜。

**第三个：内容策略简报**

```python
class XhsContentStrategyBrief(BaseModel):
    """增长策略专家输出的内容策略简报。"""
    input_evaluation: str              # 对用户输入的评估
    target_audience_persona: str       # 目标人群画像
    core_pain_point: str              # 核心痛点
    suggested_title: str              # 建议标题（带 Emoji）
    content_outline: List[str]        # 内容大纲
    engagement_strategy: str          # 互动策略
    retention_strategy: str           # 收藏策略
    seo_keywords: List[str]           # SEO 关键词
```

策略简报是下游文案和 SEO 的基础。`content_outline` 是一个列表，每个元素是大纲的一个段落方向。`seo_keywords` 给出 3 到 5 个长尾关键词，后面 SEO 专家会用到。

**第四个：文案产出**

```python
class XhsCopywritingOutput(BaseModel):
    """文案撰写师输出。"""
    title: str                    # 带 Emoji 的标题
    content: str                  # 完整正文
    picture_order: List[str]      # 图片发布顺序（image_id 列表）
    highlight_hooks: List[str]    # 钩子句（用于 A/B 测试）
```

**第五个：SEO 优化后的最终笔记**

```python
class XhsSEOOptimizedNote(BaseModel):
    """SEO 优化专家输出的最终笔记。"""
    optimization_summary: str            # 优化说明
    optimized_title: str                # 优化后的标题
    optimized_content: str              # 优化后的正文
    optimized_picture_order: List[str]  # 优化后的图片顺序
    tags: List[str]                     # 5-8 个标签
```

这是流水线的最终产物。SEO 专家在文案师写好的基础上做关键词优化，但不会改变内容的情绪和方向。

### 2.4 聚合模型

最后还有两个聚合模型，用来把多张图片的结果打包传给下游：

```python
class XhsVisualBatchReport(BaseModel):
    """多图视觉分析批量报告。"""
    user_raw_intent: str
    images_visual: List[XhsImageVisualAnalysis]
    summary: str

class XhsImageEditBatchReport(BaseModel):
    """多图编辑方案批量报告。"""
    images_edit_plan: List[XhsImageEditPlan]
    summary: str
```

阶段一和阶段二的结果会分别封装成这两个批量报告，然后序列化成 JSON 字符串传给阶段三的内容创作 Crew。

好，数据模型定义完了。现在每个 Agent 的输入输出都有了清晰的定义。接下来我们来设计 Agent 本身。

---

## 第三章：Agent 设计（13:00 – 22:00）

### 3.1 五个 Agent 的角色分工

我们的系统里有 5 个 Agent，分成两组：

**多模态组**（需要看图片）：
- **视觉分析师**（xhs_visual_analyst）：从平台审美、情绪价值、商业转化三个视角分析图片
- **图片编辑师**（xhs_image_editor）：基于视觉分析结果，出具体的编辑和 P 图方案

**纯文本组**（只处理文字）：
- **增长策略专家**（xhs_growth_strategist）：基于所有图片分析和用户意图，做内容策划
- **内容撰写师**（xhs_content_writer）：把策略转化为有情绪价值的笔记文案
- **SEO 优化专家**（xhs_seo_expert）：对文案做搜索优化，自然嵌入关键词

这个角色分工是参考了小红书 MCN 机构的真实工作流。在实际的 MCN 里，一条爆款笔记的产出也是类似的分工：有人选图评图、有人修图、有人做策划、有人写文案、有人做 SEO。我们把这个工作流翻译成了 Agent 的协作。

### 3.2 YAML 配置：角色文案

Agent 的角色定义是用 YAML 配置的。打开 `crews/config/agents.yaml`，我们看视觉分析师这个 Agent 的配置：

```yaml
xhs_visual_analyst:
  role: 资深小红书笔记视觉分析师（MCN机构方向）
  goal: 在任何图片评估场景下，优先从「平台审美 + 情绪价值 + 商业转化」
        三重视角给出客观、可执行的视觉判断...
  backstory: |
    **一、身份与背景**
    你是一位拥有 8 年以上经验的产品视觉分析师，
    长期服务于国内头部 MCN 机构...

    **二、关键知识与理论**
    - 视觉锚点理论（Visual Hook）：理解哪些元素能在 1 秒内抓住用户注意力...
    - 情绪价值传递：不仅关注产品是否清晰可见，更关注画面能否传递氛围感...

    **三、工作方法与行为习惯**
    - 始终先整体后局部：先给出画面整体印象，再下沉到主体、背景、细节...
    - 坚持结构化表达：每次输出都遵循「整体印象 → 主体与构图 → 光线与色彩 → 细节与情绪」...

    **四、行为边界（不做什么）**
    - 只负责视觉分析与评估，不进行任何图片编辑方案设计...
    - 不撰写或改写文案，不输出完整的内容结构...
  verbose: true
  allow_delegation: false
```

大家注意看这个 backstory 的结构。它分为四段：

**第一段"身份与背景"**，给 Agent 一个清晰的人设定位。这决定了它用什么视角来思考问题。

**第二段"关键知识与理论"**，注入领域知识。比如视觉锚点理论、情绪价值、小红书视觉标准。这不是让 LLM 学习这些理论，而是激活它已经预训练过的相关知识。

**第三段"工作方法与行为习惯"**，定义具体的工作流程。比如先整体后局部、坚持结构化表达。这让 Agent 的输出更稳定、更有章法。

**第四段"行为边界"**，明确告诉它不做什么。这非常关键——如果不设边界，Agent 可能会越权，比如视觉分析师可能会自作主张写文案建议。行为边界让每个 Agent 专注在自己的职责范围内。

这四段式的 backstory 结构，大家可以作为设计 Agent 角色的模板。任何一个 Agent，你只要想清楚这四段内容，基本上就能得到比较好的效果。

**为什么 backstory 写这么长？** 因为 backstory 就是 System Prompt 的一部分，它是 prompt engineering 的核心。短短一句 "你是一个图片分析专家" 的效果，和一整页详细的角色描述，差距是非常大的。长 backstory 能让 LLM 进入更专业、更稳定的角色状态。

同样的结构，其他 4 个 Agent 也各有自己的 backstory。比如增长策略专家的知识里包含了小红书的 CES 评分机制、反漏斗模型、KFS 闭环；文案师的知识包含黄金 3 秒法则、沉浸式体验描写；SEO 专家的知识包含关键词密度 2-5% 区间、多入口占位策略。这些都是真实的小红书运营方法论。

### 3.3 Python 工厂函数

配置定义好了，接下来看 Python 代码怎么把配置变成 Agent 实例。打开 `crews/xhs_note/agents.py`：

```python
from crewai import Agent
from app.crews.llm import get_llm
from app.crews.tools import AddImageToolLocal

_CONFIG_DIR = Path(__file__).resolve().parents[1] / "config"

def _load_agents_config() -> dict:
    """从 agents.yaml 读取全部 Agent 配置。"""
    with (_CONFIG_DIR / "agents.yaml").open("r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

_AGENTS_CFG = _load_agents_config()

def _agent_cfg(name: str) -> dict:
    return _AGENTS_CFG.get(name, {})
```

首先是加载配置。模块初始化时读取 `agents.yaml`，缓存到 `_AGENTS_CFG` 字典里。`_agent_cfg()` 函数根据 Agent 名称取对应的配置。

然后看工厂函数：

```python
def get_xhs_visual_analyst() -> Agent:
    """每次调用创建一个新的视觉分析 Agent 实例。"""
    cfg_visual = _agent_cfg("xhs_visual_analyst")
    return Agent(
        config=cfg_visual,
        multimodal=True,
        llm=get_llm(image_model="qwen3-vl-plus", model="qwen3-max-2026-01-23"),
        tools=[AddImageToolLocal()],
    )
```

注意这里的参数分工。

`config=cfg_visual` 传入 YAML 配置，包含 role、goal、backstory——这些"文案类"的内容全部走 YAML。

`multimodal=True` 告诉 CrewAI 这个 Agent 可以处理多模态内容。

`llm=get_llm(...)` 绑定 LLM 模型。多模态 Agent 同时绑了两个模型：`image_model` 用于看图片（qwen3-vl-plus），`model` 用于纯文本处理（qwen3-max）。

`tools=[AddImageToolLocal()]` 绑定工具。这个工具允许 Agent 加载本地图片文件，把它转成 base64 数据 URL，这样多模态 LLM 就能看到图片了。

**为什么用工厂函数而不是单例？** 这是一个容易踩的坑。如果你把 Agent 做成全局单例，在并发请求时，两个请求会共享同一个 Agent 实例，可能导致状态污染。工厂函数每次调用都创建新的 Agent，保证了线程安全。

我们来快速看一下其他几个 Agent 的工厂函数：

```python
def get_xhs_image_editor() -> Agent:
    cfg_editor = _agent_cfg("xhs_image_editor")
    return Agent(
        config=cfg_editor,
        multimodal=True,
        llm=get_llm(image_model="qwen3-vl-plus", model="qwen3-max-2026-01-23"),
        tools=[AddImageToolLocal()],
    )

def get_xhs_growth_strategist() -> Agent:
    cfg_growth = _agent_cfg("xhs_growth_strategist")
    return Agent(
        config=cfg_growth,
        tools=[IntermediateTool()],
        llm=get_llm(model="qwen3-max-2026-01-23"),
    )
```

编辑师和视觉分析师的结构一样——都是多模态、都用 AddImageToolLocal。后面三个纯文本 Agent 不需要 multimodal，工具换成了 IntermediateTool——用于保存中间思考过程。

### 3.4 工具说明

简单说一下这两个工具：

**AddImageToolLocal**：Agent 传入一个本地文件路径，工具把文件读取出来，转成 `data:image/jpeg;base64,...` 格式的数据 URL。然后 LLM 层会检测到多模态内容，自动切换到视觉理解模型。

**IntermediateTool**：Agent 把中间思考的结果传给这个工具保存。它的作用是让 Agent 能够分步思考——先保存一步的结果，再基于它做下一步推理。这对增长策略专家特别有用，因为策略制定需要多步推理。

好，Agent 设计完了。5 个 Agent、YAML 配置和 Python 工厂函数就是这些内容。接下来我们来设计 Task。

---

## 第四章：Task 设计（22:00 – 28:00）

### 4.1 YAML 模板化描述

Task 的描述也是用 YAML 配置的。打开 `crews/config/tasks.yaml`，看视觉分析任务的配置：

```yaml
task_visual_analysis:
  agent: xhs_visual_analyst
  description: |
    你需要根据用户的意图，对一张图片进行深入的视觉分析：
    1）用户的原始创作意图：{idea_text}
    2）图片信息列表：{images_info}
    请使用 AddImageTool 加载上述图片路径，对图片进行多维度观察，
    并按照 XhsImageVisualAnalysis 的字段要求，输出结构化的视觉分析结果。

    **强调输出格式：**
    - Final Answer 后面必须是纯 JSON，不要使用代码块标记
  expected_output: |
    一个能够被解析为 XhsImageVisualAnalysis 的结构化输出。
    - Final Answer 后面必须是纯 JSON
```

大家注意看两个关键点。

第一，**变量占位符**。`{idea_text}` 和 `{images_info}` 是占位符，在运行时会被替换成真实数据。这就是模板化的好处——同一个 YAML 模板可以服务于不同的输入。

第二，**输出格式约束**。我们反复强调 "Final Answer 后面必须是纯 JSON，不要使用代码块标记"。这是因为 CrewAI 使用 ReAct 模式，Agent 在推理过程中会经历 Thought → Action → Observation 的循环，最终以 "Final Answer:" 开头输出结果。如果 LLM 在 JSON 外面包了一层 \`\`\`json 代码块，Pydantic 解析就会失败。这种格式约束需要在 description 和 expected_output 里都写上，而且要写醒目。

### 4.2 Task 工厂函数

接下来看 Python 代码怎么把 YAML 模板变成 Task 实例。打开 `crews/xhs_note/tasks.py`：

```python
def build_visual_analysis_task(image: XhsImageInput, idea_text: str) -> Task:
    cfg = _get_task_config("task_visual_analysis")

    # 把图片信息序列化为 JSON
    images_json = json.dumps([{
        "image_id": image.image_id,
        "file_name": image.file_name,
        "local_path": image.local_path,
    }], ensure_ascii=False, indent=2)

    # 用真实数据替换 YAML 模板中的占位符
    description = cfg.get("description").format(
        idea_text=idea_text,
        images_info=images_json,
    )

    return Task(
        description=description,
        expected_output=cfg.get("expected_output"),
        agent=get_xhs_visual_analyst(),       # 绑定 Agent
        output_pydantic=XhsImageVisualAnalysis,  # 绑定输出模型
        async_execution=True,                    # 标记可并发
    )
```

这个函数做了三件事：

**第一**，从 YAML 读取模板，用实际数据做变量替换。`{idea_text}` 被替换成用户的真实意图，`{images_info}` 被替换成图片的 JSON 信息。

**第二**，创建 Agent 实例。`agent=get_xhs_visual_analyst()` 每次调用工厂函数创建新的 Agent。

**第三**，绑定 `output_pydantic=XhsImageVisualAnalysis`。这一行非常关键——它告诉 CrewAI："这个 Task 的 Agent 输出的 JSON 要能被解析成 XhsImageVisualAnalysis 这个 Pydantic 模型。" CrewAI 在拿到 LLM 的文本响应后，会自动尝试从中提取 JSON 并解析。

还有一个重要参数 `async_execution=True`。这表示这个 Task 可以在 Crew 内部被异步调度——当有多张图片时，多个视觉分析 Task 可以并发处理。

### 4.3 Task 间的依赖关系

视觉分析和编辑方案的 Task 是独立的，不依赖其他 Task。但内容阶段的三个 Task 之间有严格的依赖：

```python
def get_task_content_strategy() -> Task:
    # 策略 Task 没有 context 依赖
    return Task(
        ...,
        agent=get_xhs_growth_strategist(),
        output_pydantic=XhsContentStrategyBrief,
    )

def get_task_copywriting(content_strategy_task: Task) -> Task:
    return Task(
        ...,
        agent=get_xhs_content_writer(),
        context=[content_strategy_task],    # 依赖策略 Task
        output_pydantic=XhsCopywritingOutput,
    )

def get_task_seo_optimization(
    content_strategy_task: Task,
    copywriting_task: Task,
) -> Task:
    return Task(
        ...,
        agent=get_xhs_seo_expert(),
        context=[content_strategy_task, copywriting_task],  # 依赖策略和文案
        output_pydantic=XhsSEOOptimizedNote,
    )
```

注意看 `context` 参数。`get_task_copywriting` 接收 `content_strategy_task` 作为参数，放进 `context` 列表。这意味着文案 Task 在执行时，能看到策略 Task 的完整输出作为上下文。同理，SEO Task 能看到策略和文案两个 Task 的输出。

这种显式的依赖声明，让 CrewAI 知道执行顺序：策略先做，文案后做，SEO 最后做。

### 4.4 七个 Task 速览

我们总共有 7 个 Task，快速过一遍：

阶段一有两个 Task：**视觉分析**（每张图一个，可并发）和**视觉分析总结**（汇总成一句话）。

阶段二也有两个：**图片编辑方案**（每张图一个，可并发）和**编辑方案总结**（汇总成一句话）。

阶段三有三个：**内容策略** → **文案撰写** → **SEO 优化**，串行执行。

好，Task 设计完了。现在我们有了 Agent 和 Task，接下来要把它们编排起来。

---

## 第五章：流程编排（28:00 – 36:00）

### 5.1 三阶段架构设计

这是整个项目最核心的部分。打开 `crews/xhs_note/flows.py`，我们来看三阶段的编排逻辑。

整体设计是这样的：

```
阶段一：视觉分析（多图并发）
  N 张图片 → N 个视觉分析 Task + 1 个总结 Task → 1 个 Crew 执行
  产出：visual_by_id（字典，image_id → XhsImageVisualAnalysis）

阶段二：图片编辑方案（多图并发）
  N 张图片 → N 个编辑方案 Task + 1 个总结 Task → 1 个 Crew 执行
  产出：edit_by_id（字典，image_id → XhsImageEditPlan）

阶段三：内容创作（顺序执行）
  策略 Task → 文案 Task → SEO Task → 1 个 Crew 执行
  产出：XhsContentStrategyBrief + XhsCopywritingOutput + XhsSEOOptimizedNote
```

每个阶段使用独立的 Crew。为什么不把所有 Task 放一个 Crew 里？因为阶段之间有数据依赖——阶段二需要阶段一的结果，阶段三需要阶段一和二的结果。分成三个 Crew，我们可以在 Python 层控制数据的传递。

### 5.2 阶段一：视觉分析

我们来看 `_run_visual_analysis_phase()` 的实现：

```python
async def _run_visual_analysis_phase(
    idea_request: XhsNoteIdeaRequest,
) -> Tuple[Dict[str, XhsImageVisualAnalysis], str]:
    if not idea_request.images:
        return {}, ""

    # 为每张图创建一个视觉分析 Task
    tasks: List[Task] = []
    for img in idea_request.images:
        tasks.append(build_visual_analysis_task(img, idea_request.idea_text))

    # 加一个总结 Task，context 引用上面所有的视觉分析 Task
    summary_task = build_visual_analysis_summary_task(tasks)
    tasks.append(summary_task)

    # 提取所有 Task 关联的 Agent
    agents = _get_tasks_agents(tasks)

    # 创建 Crew
    crew = Crew(
        agents=agents,
        tasks=tasks,
        process=Process.sequential,
        verbose=True,
        output_log_file=get_crew_log_file_path(get_settings().log_dir),
    )

    # 带超时的异步执行
    result = await asyncio.wait_for(
        crew.akickoff(),
        timeout=get_settings().crew_execution_timeout,  # 默认 600 秒
    )
```

我来逐段解释。

首先，循环遍历所有图片，**为每张图创建一个独立的 Task**。每个 Task 有自己的 Agent 实例（工厂函数每次返回新实例）。这些 Task 的 `async_execution=True`，标记了它们可以并发执行。

然后加一个**总结 Task**。它的 `context` 参数引用了上面所有的视觉分析 Task，等前面的 Task 都完成后，它会汇总所有结果生成一句话总结。

接着创建 **Crew**。`process=Process.sequential` 表示 Task 按列表顺序执行。你可能会问：前面不是说了并发吗，为什么 Crew 是 sequential？因为 CrewAI 的并发是通过 `async_execution=True` 在 LLM 调用层实现的——同一个 Crew 内，标记了 async_execution 的 Task 会通过异步 IO 实现并发。sequential 只是 Crew 层面的调度模式。

最后，`asyncio.wait_for` 给 Crew 执行加上超时控制。默认 600 秒，也就是 10 分钟。如果某个 LLM 调用卡住了，不至于让整个服务 hang 住。

接下来是**结果提取**：

```python
    # 提取每张图的视觉分析结果
    visual_by_id: Dict[str, XhsImageVisualAnalysis] = {}
    num_images = len(idea_request.images)
    for idx in range(num_images):
        task_output = result.tasks_output[idx]
        visual: XhsImageVisualAnalysis = task_output.pydantic
        if visual and visual.image_id:
            visual_by_id[visual.image_id] = visual

    # 最后一个 Task 是总结，取 raw 文本
    summary = result.tasks_output[-1].raw if result.tasks_output else ""

    return visual_by_id, summary
```

`result.tasks_output` 是一个列表，每个元素对应一个 Task 的输出。我们用 `.pydantic` 字段取结构化的 Pydantic 对象，用 `.raw` 取原始文本。前 N 个是各图片的视觉分析结果，最后一个是总结。

### 5.3 阶段二：图片编辑方案

阶段二的结构和阶段一几乎一样，但有一个关键区别——每个 Task 的输入多了**视觉分析结果**：

```python
async def _run_image_edit_phase(
    idea_request: XhsNoteIdeaRequest,
    visual_by_id: Dict[str, XhsImageVisualAnalysis],
) -> Tuple[Dict[str, XhsImageEditPlan], str]:

    tasks: List[Task] = []
    for img in idea_request.images:
        visual = visual_by_id.get(img.image_id)
        if not visual:
            continue  # 没有视觉分析结果的图片跳过
        tasks.append(build_image_edit_task(
            idea_request.idea_text, img, visual  # 传入视觉分析结果
        ))
    ...
```

编辑师看图出方案时，不只是盲目地看图——它还能参考视觉分析师的分析结果。这就是多 Agent 协作的价值：上游 Agent 的输出成为下游 Agent 的输入上下文。

### 5.4 阶段三：内容创作

阶段三和前两个阶段有本质区别——它是**串行**的，三个 Task 之间有严格的依赖关系。

```python
async def _run_content_phase(
    idea_request: XhsNoteIdeaRequest,
    visual_batch: XhsVisualBatchReport,
    edit_batch: XhsImageEditBatchReport,
) -> Tuple[XhsContentStrategyBrief, XhsCopywritingOutput, XhsSEOOptimizedNote]:

    # 构建三个 Task，注意依赖关系
    content_strategy_task = get_task_content_strategy()
    copywriting_task = get_task_copywriting(content_strategy_task)
    seo_task = get_task_seo_optimization(content_strategy_task, copywriting_task)

    crew = Crew(
        agents=_get_tasks_agents([content_strategy_task, copywriting_task, seo_task]),
        tasks=[content_strategy_task, copywriting_task, seo_task],
        process=Process.sequential,
        verbose=True,
    )

    # 通过 inputs 传入前两阶段的汇总结果
    result = await asyncio.wait_for(
        crew.akickoff(inputs={
            "idea_text": idea_request.idea_text,
            "visual_report": visual_batch.model_dump_json(indent=2),
            "edit_report": edit_batch.model_dump_json(indent=2),
        }),
        timeout=get_settings().crew_execution_timeout,
    )
```

这里有两个重点。

**第一**，三个 Task 的构建顺序体现了依赖链。策略 Task 先创建；文案 Task 创建时传入策略 Task 作为 context；SEO Task 创建时传入策略和文案两个 Task。

**第二**，`crew.akickoff(inputs={...})`。前两阶段的结果通过 `inputs` 传入 Crew。这些 inputs 会替换 YAML 模板中的 `{idea_text}`、`{visual_report}`、`{edit_report}` 占位符。注意看，`visual_batch.model_dump_json()` 把 Pydantic 模型序列化为 JSON 字符串——这就是 Pydantic 的好处，模型天然支持序列化和反序列化。

### 5.5 总入口与最终报告

最后来看总入口 `run_xhs_note_flow()`：

```python
async def run_xhs_note_flow(
    idea_request: XhsNoteIdeaRequest,
) -> Tuple[str | None, str]:
    if not idea_request.images:
        return None, "本次请求未上传任何图片"

    try:
        # 阶段一：视觉分析
        visual_by_id, visual_summary = await _run_visual_analysis_phase(idea_request)

        # 阶段二：图片编辑方案
        edit_by_id, edit_summary = await _run_image_edit_phase(idea_request, visual_by_id)

        # 汇总为批量报告
        visual_batch = XhsVisualBatchReport(...)
        edit_batch = XhsImageEditBatchReport(...)

        # 阶段三：内容创作
        strategy, copywriting, seo_note = await _run_content_phase(
            idea_request, visual_batch, edit_batch
        )

        # 生成最终报告
        final_report = _generate_final_report(idea_request, edit_batch, seo_note)
        return final_report, ""

    except Exception as exc:
        return None, f"流程执行失败: {type(exc).__name__}: {exc}"
```

三个阶段依次执行，每个阶段的输出是下个阶段的输入。最终把 SEO 优化后的笔记和所有图片编辑方案组装成报告文本。

`_generate_final_report()` 是一个简单的字符串拼接函数，把标题、正文、标签、图片顺序、编辑方案格式化成人可读的报告。

流程编排就是这些内容。三阶段、三个 Crew、五个 Agent、七个 Task，形成了一个完整的多 Agent 协作流水线。

---

## 第六章：服务与 API 集成（36:00 – 39:00）

### 6.1 Service 层

最后我们来看怎么把这个流程接入到 Web 服务里。打开 `services/xhs_note_service.py`：

```python
async def generate_xhs_note_report(
    idea_text: str,
    files: List[UploadFile],
) -> Tuple[str | None, str]:
    settings = get_settings()

    # 校验图片数量
    if not files:
        return None, "请至少上传一张图片"
    if len(files) > settings.xhs_max_images:
        return None, f"最多允许上传 {settings.xhs_max_images} 张图片"

    # 创建临时目录
    run_id = str(uuid4())[:8]
    base_dir = Path(settings.data_output_dir) / "xhs_note" / run_id

    try:
        # 保存并压缩图片
        images = await _save_uploaded_images(
            files, base_dir,
            max_size=settings.xhs_image_max_size,
            quality=settings.xhs_image_quality,
        )

        # 构建领域模型
        idea_request = XhsNoteIdeaRequest(idea_text=idea_text, images=images)

        # 调用流程编排
        report, error = await run_xhs_note_flow(idea_request)
        return report, error

    except Exception as exc:
        return None, f"服务异常: {exc}"
    finally:
        # 无论成功失败，都清理临时目录
        _cleanup_temp_directory(base_dir)
```

Service 层做了几件事：校验输入、保存压缩图片、构建领域模型、调用 Flow、清理临时文件。注意 `finally` 块保证临时文件一定会被清理，即使出现异常。

图片压缩的逻辑在 `_save_uploaded_images()` 里，它用 Pillow 把图片长边缩到 1024 像素、JPEG 质量设为 85，这样能有效减小多模态 LLM 的输入 token 消耗。

### 6.2 API 端点

打开 `api/v1/xhs_note.py`：

```python
@router.post("/notes/report", response_model=ApiResponse[XhsNoteReportResponse])
async def create_xhs_note_report(
    idea_text: str = Form(...),
    images: List[UploadFile] = File(...),
    request_id: str = Depends(get_request_id),
    _api_key: str = Depends(require_api_key),
) -> ApiResponse[XhsNoteReportResponse]:
    try:
        final_report, error = await generate_xhs_note_report(
            idea_text=idea_text, files=images,
        )
        if error:
            return ApiResponse(code=1, message=f"生成失败: {error}", ...)
        return ApiResponse(code=0, message="ok",
            data=XhsNoteReportResponse(report=final_report), ...)
    except Exception:
        raise
```

API 层非常薄。它通过 `Form(...)` 接收文本字段，`File(...)` 接收多文件上传。`Depends(require_api_key)` 注入 API 鉴权。然后直接调用 Service 层的函数，根据返回结果封装统一的 `ApiResponse` 响应。

`code=0` 表示成功，`code=1` 表示业务错误（如 LLM 超时），系统异常交给全局异常处理器返回 500。

### 6.3 统一响应格式

所有 API 都用统一的 `ApiResponse` 格式：

```python
class ApiResponse(BaseModel, Generic[T]):
    code: int = 0          # 0 成功，非 0 失败
    message: str = "ok"
    data: T | None = None
    request_id: str        # 贯穿全链路的追踪 ID
```

`request_id` 从请求头 `X-Request-ID` 获取，如果没有则自动生成。它贯穿整个处理链路——日志、异常、响应里都有这个 ID，方便问题排查。

---

## 总结（39:00 – 40:00）

好，到这里我们完成了整个小红书爆款笔记生成系统的搭建。我们来回顾一下核心要点：

**第一，数据模型先行。** 先定义每个 Agent 的输入输出 Pydantic 模型，它们就是 Agent 之间的接口契约。模型定义好了，Agent 和 Task 的设计就水到渠成。

**第二，角色设计是灵魂。** backstory 的四段式结构——身份背景、关键知识、工作方法、行为边界——是 Agent 表现好坏的关键。长而详细的角色描述能让 LLM 进入更专业的状态。

**第三，YAML 和 Python 分离。** 文案类的内容放 YAML，结构类的配置放 Python。改 Agent 的角色定义不用动代码，改 Task 的描述模板也不用动代码。

**第四，工厂模式避免状态共享。** 每次请求创建新的 Agent 和 Task 实例，不用全局单例，避免并发时的状态污染。

**第五，三阶段编排。** 利用多模态 Agent 并发处理图片，再用纯文本 Agent 串行创作内容。每个阶段用独立的 Crew，阶段之间通过 Python 代码传递数据。

**第六，结构化输出。** `output_pydantic` 让 LLM 的自由文本输出变成可编程的结构化数据，这是整个系统能跑通的技术基石。

课后大家可以思考两个问题：如果要新增一个"评论区互动话术生成"Agent，它应该放在哪个阶段？如果图片数量很多，比如 20 张，流程的并发策略应该怎么优化？

本节课就到这里，谢谢大家。
